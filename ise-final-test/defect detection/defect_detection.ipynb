{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b30341",
   "metadata": {},
   "source": [
    "## ISE: Defect Detection Challenge\n",
    "#### Description\n",
    "In this competition, your task is to develop a model that can accurately classify source code snippets as either secure or insecure. With the rise of software vulnerabilities like resource leaks, use-after-free vulnerabilities, and denial-of-service (DoS) attacks, identifying insecure code is crucial for maintaining robust software systems.\n",
    "Participants will be provided with a dataset containing labeled code snippets. The labels indicate whether the code is secure (0) or insecure (1). Your goal is to create an effective machine learning model that can predict these labels with high accuracy.\n",
    "#### Key Objectives \n",
    "- Analyze code snippets for potential vulnerabilities.\n",
    "- Develop models to automate the classification of secure and insecure code.\n",
    "- Ensure the ROC score exceeds 0.63."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4c7c7",
   "metadata": {},
   "source": [
    "Import Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea49b3",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e963118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (20000, 3)\n",
      "Test data shape: (7000, 2)\n",
      "\n",
      "Training data columns: ['ID', 'code', 'Label']\n",
      "   ID                                               code  Label\n",
      "0   0  int page_check_range(target_ulong start, targe...      0\n",
      "1   1  static void pxa2xx_lcdc_dma0_redraw_rot0(PXA2x...      0\n",
      "2   2  void OPPROTO op_POWER_slq (void)\\n\\n{\\n\\n    u...      1\n",
      "ID       0\n",
      "code     0\n",
      "Label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
    "\n",
    "print(train_df.head(3))\n",
    "\n",
    "print(train_df.isnull().sum()) # none num "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f6239",
   "metadata": {},
   "source": [
    "## C++ Code Preprocessing Pipeline \n",
    "- Basic Text Cleaning \n",
    "- C++ Specific Normalization\n",
    "- Features Enginerring \n",
    "- Tokenization\n",
    "- Vectorization using TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f87e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_cpp_code(code):\n",
    "    # Remove single-line comments\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    \n",
    "    # Remove multi-line comments  \n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove string literals (but keep structure)\n",
    "    code = re.sub(r'\"[^\"]*\"', '\"STRING\"', code)\n",
    "    code = re.sub(r\"'[^']*'\", \"'CHAR'\", code)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    code = re.sub(r'\\s+', ' ', code)\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7656da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cpp_code(code):\n",
    "    # Normalize variable names (preserve patterns but reduce vocabulary)\n",
    "    code = re.sub(r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b', \n",
    "                  lambda m: normalize_identifier(m.group()), code)\n",
    "    \n",
    "    # Normalize numeric literals\n",
    "    code = re.sub(r'\\b\\d+\\b', 'NUM', code)\n",
    "    code = re.sub(r'\\b0x[0-9a-fA-F]+\\b', 'HEX', code)\n",
    "    \n",
    "    # Normalize function calls (keep structure)\n",
    "    code = re.sub(r'(\\w+)\\s*\\(', r'FUNC(', code)\n",
    "    \n",
    "    return code\n",
    "\n",
    "def normalize_identifier(name):\n",
    "    # Keep important C++ keywords and functions\n",
    "    cpp_keywords = {'int', 'char', 'void', 'if', 'else', 'for', 'while', \n",
    "                   'malloc', 'free', 'strcpy', 'strlen', 'memcpy', 'sizeof'}\n",
    "    \n",
    "    if name.lower() in cpp_keywords:\n",
    "        return name\n",
    "    elif len(name) <= 3:\n",
    "        return name  # Keep short vars\n",
    "    else:\n",
    "        return 'VAR'  # Generic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c569a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_security_features(code):\n",
    "    features = {}\n",
    "    \n",
    "    # Dangerous function calls\n",
    "    dangerous_funcs = ['strcpy', 'strcat', 'gets', 'sprintf', 'scanf', \n",
    "                      'malloc', 'free', 'memcpy', 'strncpy']\n",
    "    \n",
    "    for func in dangerous_funcs:\n",
    "        features[f'has_{func}'] = int(func in code.lower())\n",
    "    \n",
    "    # Memory operations\n",
    "    features['ptr_operations'] = len(re.findall(r'\\*|\\&', code))\n",
    "    features['array_access'] = len(re.findall(r'\\[.*?\\]', code))\n",
    "    features['memory_alloc'] = len(re.findall(r'malloc|calloc|new', code))\n",
    "    features['memory_free'] = len(re.findall(r'free|delete', code))\n",
    "    \n",
    "    # Control flow complexity\n",
    "    features['if_statements'] = len(re.findall(r'\\bif\\b', code))\n",
    "    features['loops'] = len(re.findall(r'\\b(for|while)\\b', code))\n",
    "    features['function_calls'] = len(re.findall(r'\\w+\\s*\\(', code))\n",
    "    \n",
    "    # Potential vulnerability patterns\n",
    "    features['buffer_ops'] = len(re.findall(r'strcpy|strcat|gets|sprintf', code))\n",
    "    features['unchecked_input'] = len(re.findall(r'scanf|gets', code))\n",
    "    features['pointer_arithmetic'] = len(re.findall(r'\\+\\+|\\-\\-|\\+\\s*\\d|\\-\\s*\\d', code))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b891b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_cpp_dataset(df):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for C++ code dataset\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'code' column and optionally 'Label' column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with processed features:\n",
    "        - normalized_code: cleaned and normalized code text\n",
    "        - security features: has_*, ptr_operations, etc.\n",
    "        - Label: original label (if present)\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    print(f\"Processing {len(df)} code samples...\")\n",
    "    \n",
    "    # Step 1: Clean the code (remove comments, normalize strings)\n",
    "    print(\"Step 1: Cleaning code...\")\n",
    "    processed_df['cleaned_code'] = processed_df['code'].apply(clean_cpp_code)\n",
    "    \n",
    "    # Step 2: Normalize the code (identifiers, numbers, functions)\n",
    "    print(\"Step 2: Normalizing code...\")\n",
    "    processed_df['normalized_code'] = processed_df['cleaned_code'].apply(normalize_cpp_code)\n",
    "    \n",
    "    # Step 3: Extract security features\n",
    "    print(\"Step 3: Extracting security features...\")\n",
    "    security_features_list = []\n",
    "    \n",
    "    for idx, code in enumerate(processed_df['code']):\n",
    "        if idx % 5000 == 0:\n",
    "            print(f\"  Processing sample {idx}/{len(processed_df)}\")\n",
    "        \n",
    "        features = extract_security_features(code)\n",
    "        security_features_list.append(features)\n",
    "    \n",
    "    # Convert security features to DataFrame and combine\n",
    "    security_df = pd.DataFrame(security_features_list)\n",
    "    \n",
    "    # Combine all features\n",
    "    result_df = pd.concat([\n",
    "        processed_df[['normalized_code']],  # Keep normalized code for TF-IDF\n",
    "        security_df,  # Add all security features\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Keep Label column if it exists (for training data)\n",
    "    if 'Label' in processed_df.columns:\n",
    "        result_df['Label'] = processed_df['Label']\n",
    "    \n",
    "    print(f\"âœ… Preprocessing complete!\")\n",
    "    print(f\"Features created: {list(security_df.columns)}\")\n",
    "    print(f\"Final shape: {result_df.shape}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989db2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4282b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Applying your preprocessing...\n",
      "Processing 20000 code samples...\n",
      "Step 1: Cleaning code...\n",
      "Step 2: Normalizing code...\n",
      "Step 3: Extracting security features...\n",
      "  Processing sample 0/20000\n",
      "  Processing sample 5000/20000\n",
      "  Processing sample 10000/20000\n",
      "  Processing sample 15000/20000\n",
      "âœ… Preprocessing complete!\n",
      "Features created: ['has_strcpy', 'has_strcat', 'has_gets', 'has_sprintf', 'has_scanf', 'has_malloc', 'has_free', 'has_memcpy', 'has_strncpy', 'ptr_operations', 'array_access', 'memory_alloc', 'memory_free', 'if_statements', 'loops', 'function_calls', 'buffer_ops', 'unchecked_input', 'pointer_arithmetic']\n",
      "Final shape: (20000, 21)\n",
      "Processing 7000 code samples...\n",
      "Step 1: Cleaning code...\n",
      "Step 2: Normalizing code...\n",
      "Step 3: Extracting security features...\n",
      "  Processing sample 0/7000\n",
      "  Processing sample 5000/7000\n",
      "âœ… Preprocessing complete!\n",
      "Features created: ['has_strcpy', 'has_strcat', 'has_gets', 'has_sprintf', 'has_scanf', 'has_malloc', 'has_free', 'has_memcpy', 'has_strncpy', 'ptr_operations', 'array_access', 'memory_alloc', 'memory_free', 'if_statements', 'loops', 'function_calls', 'buffer_ops', 'unchecked_input', 'pointer_arithmetic']\n",
      "Final shape: (7000, 20)\n",
      "Step 2: Creating TF-IDF features...\n",
      "Step 3: Using your security features...\n",
      "Final shapes - Train: (20000, 1819), Test: (7000, 1819)\n",
      "TF-IDF features: 1800, Security features: 19\n"
     ]
    }
   ],
   "source": [
    "def create_pipeline_features(train_df, test_df):\n",
    "    \"\"\"Simple pipeline using your existing preprocessing\"\"\"\n",
    "    \n",
    "    print(\"Step 1: Applying your preprocessing...\")\n",
    "    # Use your existing preprocessing function\n",
    "    train_processed = preprocess_cpp_dataset(train_df.copy())\n",
    "    test_processed = preprocess_cpp_dataset(test_df.copy())\n",
    "    \n",
    "    print(\"Step 2: Creating TF-IDF features...\")\n",
    "    # TF-IDF on normalized code\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=1800,\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        sublinear_tf = True\n",
    "    )\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    tfidf_train = vectorizer.fit_transform(train_processed['normalized_code'])\n",
    "    tfidf_test = vectorizer.transform(test_processed['normalized_code'])\n",
    "    \n",
    "    print(\"Step 3: Using your security features...\")\n",
    "    # Get your security features (numerical)\n",
    "    feature_cols = [col for col in train_processed.columns \n",
    "                   if col.startswith('has_') or col in ['ptr_operations', 'array_access', \n",
    "                   'memory_alloc', 'memory_free', 'if_statements', 'loops', \n",
    "                   'function_calls', 'buffer_ops', 'unchecked_input', 'pointer_arithmetic']]\n",
    "    \n",
    "    # Combine TF-IDF + your security features\n",
    "    X_train = np.hstack([\n",
    "        tfidf_train.toarray(),\n",
    "        train_processed[feature_cols].values\n",
    "    ])\n",
    "    \n",
    "    X_test = np.hstack([\n",
    "        tfidf_test.toarray(),\n",
    "        test_processed[feature_cols].values\n",
    "    ])\n",
    "    \n",
    "    y_train = train_processed['Label'].values\n",
    "    \n",
    "    print(f\"Final shapes - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    print(f\"TF-IDF features: {tfidf_train.shape[1]}, Security features: {len(feature_cols)}\")\n",
    "    \n",
    "    return X_train, X_test, y_train\n",
    "\n",
    "# Create features\n",
    "X_train, X_test, y_train = create_pipeline_features(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0b4924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cpu\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to check:\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b0b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "3. CodeBERT (Improved Simple Version)...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training on 16000 samples...\n",
      "   Training for 4 epochs...\n",
      "   Epoch 1, Batch 0/2000, Loss: 0.691\n",
      "   Epoch 1, Batch 100/2000, Loss: 0.687\n",
      "   Epoch 1, Batch 200/2000, Loss: 0.691\n",
      "   Epoch 1, Batch 300/2000, Loss: 0.670\n",
      "   Epoch 1, Batch 400/2000, Loss: 0.683\n",
      "   Epoch 1, Batch 500/2000, Loss: 0.653\n",
      "   Epoch 1, Batch 600/2000, Loss: 0.654\n",
      "   Epoch 1, Batch 700/2000, Loss: 0.662\n",
      "   Epoch 1, Batch 800/2000, Loss: 0.738\n",
      "   Epoch 1, Batch 900/2000, Loss: 0.720\n",
      "   Epoch 1, Batch 1000/2000, Loss: 0.507\n",
      "   Epoch 1, Batch 1100/2000, Loss: 0.759\n",
      "   Epoch 1, Batch 1200/2000, Loss: 0.630\n",
      "   Epoch 1, Batch 1300/2000, Loss: 0.535\n",
      "   Epoch 1, Batch 1400/2000, Loss: 0.668\n",
      "   Epoch 1, Batch 1500/2000, Loss: 0.626\n",
      "   Epoch 1, Batch 1600/2000, Loss: 0.602\n",
      "   Epoch 1, Batch 1700/2000, Loss: 0.665\n",
      "   Epoch 1, Batch 1800/2000, Loss: 0.574\n",
      "   Epoch 1, Batch 1900/2000, Loss: 0.480\n",
      "   Epoch 1 - Val AUC: 0.6123, Avg Loss: 0.673\n",
      "   âœ“ New best: 0.6123\n",
      "   Epoch 2, Batch 0/2000, Loss: 0.721\n",
      "   Epoch 2, Batch 100/2000, Loss: 0.777\n",
      "   Epoch 2, Batch 200/2000, Loss: 0.681\n",
      "   Epoch 2, Batch 300/2000, Loss: 0.636\n",
      "   Epoch 2, Batch 400/2000, Loss: 0.678\n",
      "   Epoch 2, Batch 500/2000, Loss: 0.702\n",
      "   Epoch 2, Batch 600/2000, Loss: 0.747\n",
      "   Epoch 2, Batch 700/2000, Loss: 0.720\n",
      "   Epoch 2, Batch 800/2000, Loss: 0.599\n",
      "   Epoch 2, Batch 900/2000, Loss: 0.608\n",
      "   Epoch 2, Batch 1000/2000, Loss: 0.636\n",
      "   Epoch 2, Batch 1100/2000, Loss: 0.640\n",
      "   Epoch 2, Batch 1200/2000, Loss: 0.739\n",
      "   Epoch 2, Batch 1300/2000, Loss: 0.684\n",
      "   Epoch 2, Batch 1400/2000, Loss: 0.702\n",
      "   Epoch 2, Batch 1500/2000, Loss: 0.607\n",
      "   Epoch 2, Batch 1600/2000, Loss: 0.677\n",
      "   Epoch 2, Batch 1700/2000, Loss: 0.623\n",
      "   Epoch 2, Batch 1800/2000, Loss: 0.710\n",
      "   Epoch 2, Batch 1900/2000, Loss: 0.534\n",
      "   Epoch 2 - Val AUC: 0.6624, Avg Loss: 0.639\n",
      "   âœ“ New best: 0.6624\n",
      "   Epoch 3, Batch 0/2000, Loss: 0.577\n",
      "   Epoch 3, Batch 100/2000, Loss: 0.585\n",
      "   Epoch 3, Batch 200/2000, Loss: 0.754\n",
      "   Epoch 3, Batch 300/2000, Loss: 0.784\n",
      "   Epoch 3, Batch 400/2000, Loss: 0.686\n",
      "   Epoch 3, Batch 500/2000, Loss: 0.620\n",
      "   Epoch 3, Batch 600/2000, Loss: 0.603\n",
      "   Epoch 3, Batch 700/2000, Loss: 0.418\n",
      "   Epoch 3, Batch 800/2000, Loss: 0.623\n",
      "   Epoch 3, Batch 900/2000, Loss: 0.686\n",
      "   Epoch 3, Batch 1000/2000, Loss: 0.553\n",
      "   Epoch 3, Batch 1100/2000, Loss: 0.413\n",
      "   Epoch 3, Batch 1200/2000, Loss: 0.486\n",
      "   Epoch 3, Batch 1300/2000, Loss: 0.557\n",
      "   Epoch 3, Batch 1400/2000, Loss: 0.717\n",
      "   Epoch 3, Batch 1500/2000, Loss: 0.696\n",
      "   Epoch 3, Batch 1600/2000, Loss: 0.513\n",
      "   Epoch 3, Batch 1700/2000, Loss: 0.553\n",
      "   Epoch 3, Batch 1800/2000, Loss: 0.584\n",
      "   Epoch 3, Batch 1900/2000, Loss: 0.510\n",
      "   Epoch 3 - Val AUC: 0.6860, Avg Loss: 0.607\n",
      "   âœ“ New best: 0.6860\n",
      "   Epoch 4, Batch 0/2000, Loss: 0.661\n",
      "   Epoch 4, Batch 100/2000, Loss: 1.034\n",
      "   Epoch 4, Batch 200/2000, Loss: 0.327\n",
      "   Epoch 4, Batch 300/2000, Loss: 0.642\n",
      "   Epoch 4, Batch 400/2000, Loss: 0.714\n",
      "   Epoch 4, Batch 500/2000, Loss: 0.531\n",
      "   Epoch 4, Batch 600/2000, Loss: 0.609\n",
      "   Epoch 4, Batch 700/2000, Loss: 0.729\n",
      "   Epoch 4, Batch 800/2000, Loss: 0.466\n",
      "   Epoch 4, Batch 900/2000, Loss: 0.617\n",
      "   Epoch 4, Batch 1000/2000, Loss: 0.461\n",
      "   Epoch 4, Batch 1100/2000, Loss: 0.526\n",
      "   Epoch 4, Batch 1200/2000, Loss: 0.437\n",
      "   Epoch 4, Batch 1300/2000, Loss: 0.679\n",
      "   Epoch 4, Batch 1400/2000, Loss: 0.638\n",
      "   Epoch 4, Batch 1500/2000, Loss: 0.578\n",
      "   Epoch 4, Batch 1600/2000, Loss: 0.557\n",
      "   Epoch 4, Batch 1700/2000, Loss: 0.767\n",
      "   Epoch 4, Batch 1800/2000, Loss: 0.636\n",
      "   Epoch 4, Batch 1900/2000, Loss: 0.528\n",
      "   Epoch 4 - Val AUC: 0.6988, Avg Loss: 0.557\n",
      "   âœ“ New best: 0.6988\n",
      "   ðŸŽ¯ Final CodeBERT AUC: 0.6988\n",
      "   âœ… SUCCESS! Beat target of 0.63\n",
      "\n",
      "Best Model: CodeBERT (ROC-AUC: 0.6988)\n",
      "Target (>0.63): ACHIEVED\n"
     ]
    }
   ],
   "source": [
    "def train_models_with_codebert(X_train, y_train, train_df, test_df):\n",
    "    \"\"\"Enhanced training with CodeBERT option\"\"\"\n",
    "    \n",
    "    global train_test_split, roc_auc_score\n",
    "\n",
    "    # Your existing models first\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                random_state=42, stratify=y_train)\n",
    "    \n",
    "    models = {}\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Training models...\")\n",
    "    \n",
    "    # # 1. Your existing Logistic Regression\n",
    "    # print(\"1. Logistic Regression...\")\n",
    "    # lr = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "    # lr.fit(X_tr, y_tr)\n",
    "    # lr_pred = lr.predict_proba(X_val)[:, 1]\n",
    "    # lr_score = roc_auc_score(y_val, lr_pred)\n",
    "    # models['Logistic Regression'] = lr\n",
    "    # results['Logistic Regression'] = lr_score\n",
    "    # print(f\"   ROC-AUC: {lr_score:.4f}\")\n",
    "    \n",
    "    # # 2. Your existing XGBoost\n",
    "    # print(\"2. XGBoost...\")\n",
    "    # scale_pos_weight = len(y_tr[y_tr==0]) / len(y_tr[y_tr==1])\n",
    "    # xgb_model = xgb.XGBClassifier(\n",
    "    #     n_estimators=1200, max_depth=8, learning_rate=0.1,\n",
    "    #     subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=1.0,\n",
    "    #     min_child_weight=3, gamma=0.1, random_state=42,\n",
    "    #     scale_pos_weight=scale_pos_weight, eval_metric='auc'\n",
    "    # )\n",
    "    # xgb_model.fit(X_tr, y_tr)\n",
    "    # xgb_pred = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    # xgb_score = roc_auc_score(y_val, xgb_pred)\n",
    "    # models['XGBoost'] = xgb_model\n",
    "    # results['XGBoost'] = xgb_score\n",
    "    # print(f\"   ROC-AUC: {xgb_score:.4f}\")\n",
    "    \n",
    "    # 3. CodeBERT (Improved Simple Version)\n",
    "    print(\"3. CodeBERT (Improved Simple Version)...\")\n",
    "    try:\n",
    "        import time\n",
    "        import torch\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        classifier = CodeBERTClassifier(max_length=384)  # Longer sequences\n",
    "        \n",
    "        # Use MORE data - this is key!\n",
    "        subset_size = 15000  # Much more data\n",
    "        train_texts = train_df['code'].tolist()\n",
    "        train_labels = train_df['Label'].tolist()\n",
    "        \n",
    "        cb_train_texts, cb_val_texts, cb_train_labels, cb_val_labels = train_test_split(\n",
    "            train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    "        )\n",
    "        \n",
    "        print(f\"   Training on {len(cb_train_texts)} samples...\")\n",
    "        \n",
    "        # Better preprocessing\n",
    "        def better_preprocess(code):\n",
    "            # Keep more structure\n",
    "            code = code.replace('\\n', ' NEWLINE ')\n",
    "            code = code.replace('\\t', ' TAB ')\n",
    "            return code\n",
    "        \n",
    "        # Apply better preprocessing\n",
    "        cb_train_texts = [better_preprocess(text) for text in cb_train_texts]\n",
    "        cb_val_texts = [better_preprocess(text) for text in cb_val_texts]\n",
    "        \n",
    "        # Tokenize\n",
    "        train_encodings = classifier.tokenizer(\n",
    "            cb_train_texts, truncation=True, padding=True, max_length=384, return_tensors=\"pt\"\n",
    "        )\n",
    "        val_encodings = classifier.tokenizer(\n",
    "            cb_val_texts, truncation=True, padding=True, max_length=384, return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Dataset\n",
    "        class SimpleDataset:\n",
    "            def __init__(self, encodings, labels):\n",
    "                self.encodings = encodings\n",
    "                self.labels = labels\n",
    "            def __getitem__(self, idx):\n",
    "                item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "                item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "                return item\n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "        \n",
    "        train_dataset = SimpleDataset(train_encodings, cb_train_labels)\n",
    "        val_dataset = SimpleDataset(val_encodings, cb_val_labels)\n",
    "        \n",
    "        # Better dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Slightly smaller batch\n",
    "        val_loader = DataLoader(val_dataset, batch_size=24, shuffle=False)\n",
    "        \n",
    "        # Better training setup\n",
    "        optimizer = torch.optim.AdamW(classifier.model.parameters(), lr=1e-5, weight_decay=0.01)  # Lower LR\n",
    "        \n",
    "        print(f\"   Training for 4 epochs...\")  # More epochs\n",
    "        best_auc = 0\n",
    "        \n",
    "        for epoch in range(4):  # More training\n",
    "            classifier.model.train()\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                input_ids = batch['input_ids'].to(classifier.device)\n",
    "                attention_mask = batch['attention_mask'].to(classifier.device)\n",
    "                labels = batch['labels'].to(classifier.device)\n",
    "                \n",
    "                outputs = classifier.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                if batch_idx % 100 == 0:\n",
    "                    print(f\"   Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.3f}\")\n",
    "            \n",
    "            # Validation\n",
    "            classifier.model.eval()\n",
    "            val_preds = []\n",
    "            val_labels_list = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(classifier.device)\n",
    "                    attention_mask = batch['attention_mask'].to(classifier.device)\n",
    "                    labels = batch['labels'].to(classifier.device)\n",
    "                    \n",
    "                    outputs = classifier.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    probs = torch.softmax(outputs.logits, dim=-1)[:, 1]\n",
    "                    \n",
    "                    val_preds.extend(probs.cpu().numpy())\n",
    "                    val_labels_list.extend(labels.cpu().numpy())\n",
    "            \n",
    "            val_auc = roc_auc_score(val_labels_list, val_preds)\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"   Epoch {epoch+1} - Val AUC: {val_auc:.4f}, Avg Loss: {avg_loss:.3f}\")\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                print(f\"   âœ“ New best: {best_auc:.4f}\")\n",
    "        \n",
    "        models['CodeBERT'] = classifier\n",
    "        results['CodeBERT'] = best_auc\n",
    "        print(f\"   ðŸŽ¯ Final CodeBERT AUC: {best_auc:.4f}\")\n",
    "        \n",
    "        if best_auc > 0.63:\n",
    "            print(f\"   âœ… SUCCESS! Beat target of 0.63\")\n",
    "        else:\n",
    "            print(f\"   âŒ Still below 0.63, need: {0.63 - best_auc:.3f} more\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   CodeBERT failed: {str(e)}\")\n",
    "        \n",
    "        # 4. Your existing Neural Network as fallback\n",
    "        nn_model = keras.Sequential([\n",
    "            layers.Dense(1024, activation='relu', input_shape=(X_tr.shape[1],)),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        nn_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001), \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=[keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=5, min_lr=1e-6, mode='max')\n",
    "        \n",
    "        nn_model.fit(X_tr, y_tr, epochs=40, batch_size=64, \n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "        \n",
    "        nn_pred = nn_model.predict(X_val)\n",
    "        nn_score = roc_auc_score(y_val, nn_pred)\n",
    "        models['Neural Network'] = nn_model\n",
    "        results['Neural Network'] = nn_score\n",
    "        print(f\"   Neural Network ROC-AUC: {nn_score:.4f}\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = max(results, key=results.get)\n",
    "    best_model = models[best_model_name]\n",
    "    best_score = results[best_model_name]\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name} (ROC-AUC: {best_score:.4f})\")\n",
    "    print(f\"Target (>0.63): {'ACHIEVED' if best_score > 0.63 else 'NOT ACHIEVED'}\")\n",
    "    \n",
    "    return best_model, best_score, best_model_name\n",
    "\n",
    "# Train models\n",
    "best_model, best_score, best_model_name = train_models_with_codebert(X_train, y_train, train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "195a4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with CodeBERT...\n",
      "   Processed 0/7000\n",
      "   Processed 4000/7000\n",
      "âœ… Done! 7000 predictions saved.\n"
     ]
    }
   ],
   "source": [
    "# Simple CodeBERT Prediction (Batched)\n",
    "print(\"Making predictions with CodeBERT...\")\n",
    "\n",
    "# Clear GPU memory first\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get trained model\n",
    "codebert_model = best_model\n",
    "codebert_model.model.eval()\n",
    "\n",
    "# Process in small batches\n",
    "batch_size = 32\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_df), batch_size):\n",
    "        # Get batch\n",
    "        batch_texts = test_df['code'].iloc[i:i+batch_size].tolist()\n",
    "        \n",
    "        def better_preprocess(code):\n",
    "            code = code.replace('\\n', ' NEWLINE ')\n",
    "            code = code.replace('\\t', ' TAB ')\n",
    "            return code\n",
    "\n",
    "        batch_texts = [better_preprocess(text) for text in batch_texts]\n",
    "        \n",
    "        # Tokenize batch\n",
    "        batch_inputs = codebert_model.tokenizer(\n",
    "            batch_texts, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=384, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move to GPU\n",
    "        batch_inputs = {k: v.to(codebert_model.device) for k, v in batch_inputs.items()}\n",
    "        \n",
    "        # Predict\n",
    "        outputs = codebert_model.model(**batch_inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[:, 1]\n",
    "        predictions = (probs > 0.5).int().cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        del batch_inputs, outputs, probs, predictions\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Progress\n",
    "        if i % 500 == 0:\n",
    "            print(f\"   Processed {i}/{len(test_df)}\")\n",
    "\n",
    "# Save\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'Label': all_predictions\n",
    "})\n",
    "submission.to_csv('data/submission.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Done! {len(all_predictions)} predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "844ffaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on full dataset...\n",
      "Generating predictions...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CodeBERTClassifier' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     test_predictions = (test_probabilities > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# Convert to 0 or 1\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Sklearn models - retrain and get predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mfinal_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m(X_train, y_train)\n\u001b[32m     16\u001b[39m     test_predictions = final_model.predict(X_test)  \u001b[38;5;66;03m# Direct binary predictions\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Create submission file with binary labels\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'CodeBERTClassifier' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Train final model and generate predictions\n",
    "print(\"Training final model on full dataset...\")\n",
    "final_model = best_model\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(\"Generating predictions...\")\n",
    "\n",
    "# Get probabilities first, then convert to binary labels\n",
    "if 'Neural Network' in str(type(best_model)) or hasattr(best_model, 'predict') and not hasattr(best_model, 'predict_proba'):\n",
    "    # Neural Network case - gives probabilities, convert to labels\n",
    "    test_probabilities = final_model.predict(X_test).flatten()\n",
    "    test_predictions = (test_probabilities > 0.5).astype(int)  # Convert to 0 or 1\n",
    "else:\n",
    "    # Sklearn models - retrain and get predictions\n",
    "    final_model.fit(X_train, y_train)\n",
    "    test_predictions = final_model.predict(X_test)  # Direct binary predictions\n",
    "\n",
    "# Create submission file with binary labels\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],           \n",
    "    'Label': test_predictions      \n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('data/submission.csv', index=False)\n",
    "print(f\"âœ… Submission saved! Shape: {submission.shape}\")\n",
    "print(f\"Label distribution: {pd.Series(test_predictions).value_counts().sort_index()}\")\n",
    "print(submission.head())\n",
    "# print(test_df.shape)\n",
    "\n",
    "# Verify format\n",
    "print(f\"\\nSubmission format check:\")\n",
    "print(f\"- Unique labels: {sorted(submission['Label'].unique())}\")\n",
    "print(f\"- Should be: [0, 1] only\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## CodeBERT Integration for Improved Performance\n",
    "\n",
    "Several options to enhance the model:\n",
    "\n",
    "### Option 1: CodeBERT (Recommended)\n",
    "- **Model**: `microsoft/codebert-base`\n",
    "- **Advantages**: Specifically designed for code understanding\n",
    "- **Expected ROC-AUC**: 0.75-0.85+ (significant improvement)\n",
    "\n",
    "### Option 2: GraphCodeBERT \n",
    "- **Model**: `microsoft/graphcodebert-base`\n",
    "- **Advantages**: Incorporates code structure (AST)\n",
    "- **Best for**: Complex vulnerability patterns\n",
    "\n",
    "### Option 3: CodeT5\n",
    "- **Model**: `Salesforce/codet5-base`\n",
    "- **Advantages**: Text-to-code and code-to-text understanding\n",
    "\n",
    "### Implementation Strategy:\n",
    "1. Fine-tune pre-trained CodeBERT on your dataset\n",
    "2. Use code snippets directly (minimal preprocessing)\n",
    "3. Leverage transfer learning for better performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b6a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Option 1: Pure CodeBERT (Recommended)\\nclassifier, trainer, test_predictions, test_probabilities, validation_score = train_codebert_model(train_df, test_df)\\n\\n# Create submission\\nsubmission = pd.DataFrame({\\n    \\'ID\\': test_df[\\'ID\\'],\\n    \\'Label\\': test_predictions\\n})\\nsubmission.to_csv(\\'data/codebert_submission.csv\\', index=False)\\nprint(f\"CodeBERT ROC-AUC: {validation_score:.4f}\")\\n\\n# Option 2: Ensemble with existing models\\nensemble_labels, ensemble_probs = ensemble_codebert_with_existing(train_df, test_df, your_existing_probabilities)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "class CodeBERTClassifier:\n",
    "    def __init__(self, model_name=\"microsoft/codebert-base\", max_length=512):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize tokenizer and model with safetensors\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_labels=2,\n",
    "            problem_type=\"single_label_classification\",\n",
    "            use_safetensors=True  # Force safetensors format\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def preprocess_code(self, code_text):\n",
    "        \"\"\"Minimal preprocessing for CodeBERT\"\"\"\n",
    "        code_text = ' '.join(code_text.split())\n",
    "        if len(code_text) > 2000:\n",
    "            code_text = code_text[:2000]\n",
    "        return code_text\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics for evaluation\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.softmax(torch.tensor(predictions), dim=-1)[:, 1]  # Get positive class probabilities\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(labels, predictions)\n",
    "    \n",
    "    # Accuracy with threshold 0.5\n",
    "    pred_labels = (predictions > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(labels, pred_labels)\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def train_codebert_model(train_df, test_df):\n",
    "    \"\"\"Complete training pipeline for CodeBERT\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Starting CodeBERT training...\")\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = CodeBERTClassifier()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"ðŸ“ Preparing training data...\")\n",
    "    train_texts = train_df['code'].tolist()\n",
    "    train_labels = train_df['Label'].tolist()\n",
    "    \n",
    "    # Create train/validation split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_texts_split, val_texts_split, train_labels_split, val_labels_split = train_test_split(\n",
    "        train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    train_dataset = classifier.tokenize_data(train_texts_split, train_labels_split)\n",
    "    val_dataset = classifier.tokenize_data(val_texts_split, val_labels_split)\n",
    "    test_dataset = classifier.tokenize_data(test_df['code'].tolist())\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./codebert_results',\n",
    "        num_train_epochs=3,              # Start with 3 epochs\n",
    "        per_device_train_batch_size=8,   # Adjust based on GPU memory\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_steps=1000,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        greater_is_better=True,\n",
    "        report_to=None,  # Disable wandb/tensorboard\n",
    "        dataloader_num_workers=0,  # Prevent multiprocessing issues\n",
    "    )\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=classifier.tokenizer)\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=classifier.model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=classifier.tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"ðŸ‹ï¸ Training model...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    print(\"ðŸ“Š Evaluating on validation set...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Validation ROC-AUC: {eval_results['eval_roc_auc']:.4f}\")\n",
    "    print(f\"Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "    \n",
    "    # Generate predictions on test set\n",
    "    print(\"ðŸ”® Generating test predictions...\")\n",
    "    test_predictions = trainer.predict(test_dataset)\n",
    "    test_probs = torch.softmax(torch.tensor(test_predictions.predictions), dim=-1)[:, 1]\n",
    "    test_labels = (test_probs > 0.5).int().numpy()\n",
    "    \n",
    "    return classifier, trainer, test_labels, test_probs.numpy(), eval_results['eval_roc_auc']\n",
    "\n",
    "# Alternative: Ensemble CodeBERT with your existing models\n",
    "def ensemble_codebert_with_existing(train_df, test_df, existing_predictions):\n",
    "    \"\"\"Combine CodeBERT with your existing models\"\"\"\n",
    "    \n",
    "    # Train CodeBERT\n",
    "    classifier, trainer, codebert_test_labels, codebert_test_probs, codebert_score = train_codebert_model(train_df, test_df)\n",
    "    \n",
    "    # Simple ensemble: average probabilities\n",
    "    # Convert your existing predictions to probabilities if needed\n",
    "    if hasattr(existing_predictions, 'predict_proba'):\n",
    "        existing_probs = existing_predictions\n",
    "    else:\n",
    "        existing_probs = existing_predictions  # Assume already probabilities\n",
    "    \n",
    "    # Weighted ensemble (CodeBERT likely better, so higher weight)\n",
    "    ensemble_probs = 0.7 * codebert_test_probs + 0.3 * existing_probs\n",
    "    ensemble_labels = (ensemble_probs > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"CodeBERT ROC-AUC: {codebert_score:.4f}\")\n",
    "    print(f\"Ensemble predictions ready!\")\n",
    "    \n",
    "    return ensemble_labels, ensemble_probs\n",
    "\n",
    "# Usage example:\n",
    "\"\"\"\n",
    "# Option 1: Pure CodeBERT (Recommended)\n",
    "classifier, trainer, test_predictions, test_probabilities, validation_score = train_codebert_model(train_df, test_df)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'Label': test_predictions\n",
    "})\n",
    "submission.to_csv('data/codebert_submission.csv', index=False)\n",
    "print(f\"CodeBERT ROC-AUC: {validation_score:.4f}\")\n",
    "\n",
    "# Option 2: Ensemble with existing models\n",
    "ensemble_labels, ensemble_probs = ensemble_codebert_with_existing(train_df, test_df, your_existing_probabilities)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
