    print("3. Neural Network with Extended GridSearchCV...")

    from sklearn.model_selection import StratifiedKFold
    from itertools import product
    import tensorflow as tf

    def create_nn_model(neurons1, neurons2, neurons3, dropout1, dropout2, learning_rate):
        """Create neural network model with specified parameters"""
        model = keras.Sequential([
            layers.Dense(neurons1, activation='relu', input_shape=(X_tr.shape[1],)),
            layers.Dropout(dropout1),
            
            layers.Dense(neurons2, activation='relu'),
            layers.Dropout(dropout1),

            layers.Dense(neurons3, activation='relu'),
            layers.Dropout(dropout2),

            layers.Dense(128, activation='relu'),
            layers.Dropout(dropout2),
            
            layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999), 
            loss='binary_crossentropy', 
            metrics=[keras.metrics.AUC(name='auc')]
        )
        return model

    # EXPANDED parameter grid - Many more combinations!
    param_grid = {
        'neurons1': [256, 512, 768, 1024, 1536],        # 5 options
        'neurons2': [128, 256, 384, 512, 768],          # 5 options
        'neurons3': [64, 128, 192, 256, 384],           # 5 options
        'dropout1': [0.3, 0.4, 0.5, 0.6, 0.7],         # 5 options
        'dropout2': [0.2, 0.3, 0.4, 0.5, 0.6],         # 5 options
        'learning_rate': [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02],  # 6 options
        'batch_size': [16, 32, 48, 64, 96],             # 5 options
        'epochs': [25, 30, 35, 40, 50]                  # 5 options
    }

    # Generate ALL parameter combinations from param_grid
    param_keys = list(param_grid.keys())
    param_values = list(param_grid.values())
    all_combinations = list(product(*param_values))

    # Convert to list of dictionaries
    param_combinations = []
    for combination in all_combinations:
        param_dict = dict(zip(param_keys, combination))
        param_combinations.append(param_dict)

    total_combinations = len(param_combinations)
    print(f"   Total possible combinations: {total_combinations:,}")

    # For practical reasons, let's test a good sample
    # You can adjust this number based on your time/compute budget
    test_combinations = 50  # Test 50 random combinations
    print(f"   Testing {test_combinations} random combinations...")

    # Randomly sample combinations for efficiency
    import random
    random.seed(42)  # For reproducibility
    sampled_combinations = random.sample(param_combinations, min(test_combinations, total_combinations))

    print("   Starting grid search...")

    # Manual GridSearchCV with cross-validation
    best_score = 0
    best_params = None
    best_model = None
    results_log = []

    for i, params in enumerate(sampled_combinations):
        print(f"\n   üîÑ Testing combination {i+1}/{len(sampled_combinations)}")
        print(f"   üìã Params: neurons=[{params['neurons1']},{params['neurons2']},{params['neurons3']}], "
            f"dropout=[{params['dropout1']},{params['dropout2']}], lr={params['learning_rate']}, "
            f"batch={params['batch_size']}, epochs={params['epochs']}")
        
        # 3-Fold Cross Validation
        kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
        fold_scores = []
        
        for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tr, y_tr)):
            print(f"     Fold {fold+1}/3...", end=" ")
            
            # Split data
            X_fold_train, X_fold_val = X_tr[train_idx], X_tr[val_idx]
            y_fold_train, y_fold_val = y_tr[train_idx], y_tr[val_idx]
            
            # Create and train model
            model = create_nn_model(
                params['neurons1'], params['neurons2'], params['neurons3'],
                params['dropout1'], params['dropout2'], params['learning_rate']
            )
            
            # Callbacks
            early_stop = EarlyStopping(
                monitor='val_auc',
                patience=6,
                restore_best_weights=True,
                mode='max',
                verbose=0
            )
            
            # Train
            history = model.fit(
                X_fold_train, y_fold_train,
                epochs=params['epochs'],
                batch_size=params['batch_size'],
                validation_data=(X_fold_val, y_fold_val),
                callbacks=[early_stop],
                verbose=0
            )
            
            # Evaluate
            fold_pred = model.predict(X_fold_val, verbose=0).flatten()
            fold_score = roc_auc_score(y_fold_val, fold_pred)
            fold_scores.append(fold_score)
            
            print(f"AUC: {fold_score:.4f}")
            
            # Clear model to save memory
            del model
            tf.keras.backend.clear_session()
        
        # Calculate mean score
        mean_score = np.mean(fold_scores)
        std_score = np.std(fold_scores)
        
        print(f"   üìä Mean CV AUC: {mean_score:.4f} (+/- {std_score:.4f})")
        
        # Log results
        results_log.append({
            'params': params,
            'mean_score': mean_score,
            'std_score': std_score,
            'fold_scores': fold_scores
        })
        
        # Track best
        if mean_score > best_score:
            best_score = mean_score
            best_params = params
            print(f"   ‚úÖ NEW BEST SCORE!")
        else:
            print(f"   Current best: {best_score:.4f}")

    # Train final model with best parameters
    print(f"\nüèÜ BEST PARAMETERS FOUND:")
    for key, value in best_params.items():
        print(f"   {key}: {value}")
    print(f"üèÜ Best CV AUC: {best_score:.4f}")

    print("   Training final model with best parameters...")
    final_nn_model = create_nn_model(
        best_params['neurons1'], best_params['neurons2'], best_params['neurons3'],
        best_params['dropout1'], best_params['dropout2'], best_params['learning_rate']
    )

    # Final training with best parameters
    final_history = final_nn_model.fit(
        X_tr, y_tr,
        epochs=best_params['epochs'] + 15,  # Extra epochs for final training
        batch_size=best_params['batch_size'],
        validation_data=(X_val, y_val),
        callbacks=[EarlyStopping(monitor='val_auc', patience=12, restore_best_weights=True, mode='max')],
        verbose=1
    )

    # Final evaluation
    nn_pred = final_nn_model.predict(X_val, verbose=0).flatten()
    nn_score = roc_auc_score(y_val, nn_pred)

    nn_train_pred = final_nn_model.predict(X_tr, verbose=0).flatten()
    nn_train_score = roc_auc_score(y_tr, nn_train_pred)

    models['Neural Network'] = final_nn_model
    results['Neural Network'] = nn_score

    print(f"   Final Train ROC-AUC: {nn_train_score:.4f}")
    print(f"   Final Val ROC-AUC: {nn_score:.4f}")
    print(f"   Overfitting check: {nn_train_score - nn_score:.4f}")

    # Display top 10 results
    print(f"\nüìä TOP 10 COMBINATIONS:")
    for i, result in enumerate(sorted(results_log, key=lambda x: x['mean_score'], reverse=True)[:10]):
        print(f"   Rank {i+1}: {result['mean_score']:.4f} (+/- {result['std_score']:.4f})")
        params = result['params']
        print(f"           neurons=[{params['neurons1']},{params['neurons2']},{params['neurons3']}], "
            f"dropout=[{params['dropout1']},{params['dropout2']}], lr={params['learning_rate']}")